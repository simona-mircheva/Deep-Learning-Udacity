{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Debugger and Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting smdebug\n",
      "  Using cached smdebug-1.0.12-py2.py3-none-any.whl (270 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.20.3)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (3.19.1)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.20.23)\n",
      "Collecting pyinstrument==3.4.2\n",
      "  Using cached pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from smdebug) (20.1)\n",
      "Collecting pyinstrument-cext>=0.2.2\n",
      "  Using cached pyinstrument_cext-0.2.4-cp37-cp37m-manylinux2010_x86_64.whl (20 kB)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.23 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (1.23.23)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->smdebug) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->smdebug) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.23->boto3>=1.10.32->smdebug) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.23->boto3>=1.10.32->smdebug) (1.26.7)\n",
      "Installing collected packages: pyinstrument-cext, pyinstrument, smdebug\n",
      "Successfully installed pyinstrument-3.4.2 pyinstrument-cext-0.2.4 smdebug-1.0.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"batch_size\": 2048,\n",
    "    \"gpu\": True,\n",
    "    \"epoch\": 2,\n",
    "    \"model\": \"resnet50\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules = [Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),]#TODO: Can you add the rules you want to track]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.debugger import DebuggerHookConfig, ProfilerConfig, FrameworkProfile\n",
    "\n",
    "#TODO: Can you create the profiler and debugger configs\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")\n",
    "debugger_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"pytorch_cifar_profiling.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    profiler_config=profiler_config,\n",
    "    rules=rules,\n",
    ")#TODO: Create the estimator to train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-20 10:57:34 Starting - Starting the training job...\n",
      "2022-01-20 10:57:36 Starting - Launching requested ML instancesVanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: InProgress\n",
      "LossNotDecreasing: InProgress\n",
      "LowGPUUtilization: InProgress\n",
      "ProfilerReport: InProgress\n",
      "......\n",
      "2022-01-20 10:59:00 Starting - Preparing the instances for training.........\n",
      "2022-01-20 11:00:29 Downloading - Downloading input data\n",
      "2022-01-20 11:00:29 Training - Downloading the training image.....................\n",
      "2022-01-20 11:04:03 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-01-20 11:03:57,883 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-01-20 11:03:57,906 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-01-20 11:03:57,916 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-01-20 11:03:58,554 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 2048,\n",
      "        \"epoch\": 2,\n",
      "        \"model\": \"resnet50\",\n",
      "        \"gpu\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-01-20-10-57-34-170\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-264082167679/pytorch-training-2022-01-20-10-57-34-170/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pytorch_cifar_profiling\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pytorch_cifar_profiling.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":2048,\"epoch\":2,\"gpu\":true,\"model\":\"resnet50\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pytorch_cifar_profiling.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pytorch_cifar_profiling\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-264082167679/pytorch-training-2022-01-20-10-57-34-170/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":2048,\"epoch\":2,\"gpu\":true,\"model\":\"resnet50\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-01-20-10-57-34-170\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-264082167679/pytorch-training-2022-01-20-10-57-34-170/source/sourcedir.tar.gz\",\"module_name\":\"pytorch_cifar_profiling\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pytorch_cifar_profiling.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"2048\",\"--epoch\",\"2\",\"--gpu\",\"True\",\"--model\",\"resnet50\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=2048\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCH=2\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL=resnet50\u001b[0m\n",
      "\u001b[34mSM_HP_GPU=true\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 pytorch_cifar_profiling.py --batch_size 2048 --epoch 2 --gpu True --model resnet50\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:01.863 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:02.004 algo-1:26 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34mbatch_size:2048\u001b[0m\n",
      "\u001b[34mepoch:2\u001b[0m\n",
      "\u001b[34mgpu:True\u001b[0m\n",
      "\u001b[34mmodel:resnet50\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:10.017 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:10.019 algo-1:26 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:10.020 algo-1:26 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:10.020 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\u001b[0m\n",
      "\u001b[34mExtracting ./data/cifar-10-python.tar.gz to ./data\u001b[0m\n",
      "\u001b[34mFiles already downloaded and verified\u001b[0m\n",
      "\u001b[34mSTART TRAINING\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.922 algo-1:26 INFO hook.py:591] name:conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.923 algo-1:26 INFO hook.py:591] name:bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.923 algo-1:26 INFO hook.py:591] name:bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.923 algo-1:26 INFO hook.py:591] name:layer1.0.conv1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.924 algo-1:26 INFO hook.py:591] name:layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.924 algo-1:26 INFO hook.py:591] name:layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.924 algo-1:26 INFO hook.py:591] name:layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.925 algo-1:26 INFO hook.py:591] name:layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.925 algo-1:26 INFO hook.py:591] name:layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.925 algo-1:26 INFO hook.py:591] name:layer1.0.conv3.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.926 algo-1:26 INFO hook.py:591] name:layer1.0.bn3.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.926 algo-1:26 INFO hook.py:591] name:layer1.0.bn3.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.926 algo-1:26 INFO hook.py:591] name:layer1.0.downsample.0.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.927 algo-1:26 INFO hook.py:591] name:layer1.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.927 algo-1:26 INFO hook.py:591] name:layer1.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.928 algo-1:26 INFO hook.py:591] name:layer1.1.conv1.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.928 algo-1:26 INFO hook.py:591] name:layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.928 algo-1:26 INFO hook.py:591] name:layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.929 algo-1:26 INFO hook.py:591] name:layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.929 algo-1:26 INFO hook.py:591] name:layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.929 algo-1:26 INFO hook.py:591] name:layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.930 algo-1:26 INFO hook.py:591] name:layer1.1.conv3.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.930 algo-1:26 INFO hook.py:591] name:layer1.1.bn3.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.930 algo-1:26 INFO hook.py:591] name:layer1.1.bn3.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.931 algo-1:26 INFO hook.py:591] name:layer1.2.conv1.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.931 algo-1:26 INFO hook.py:591] name:layer1.2.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.931 algo-1:26 INFO hook.py:591] name:layer1.2.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.932 algo-1:26 INFO hook.py:591] name:layer1.2.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.932 algo-1:26 INFO hook.py:591] name:layer1.2.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.933 algo-1:26 INFO hook.py:591] name:layer1.2.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.933 algo-1:26 INFO hook.py:591] name:layer1.2.conv3.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.933 algo-1:26 INFO hook.py:591] name:layer1.2.bn3.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.934 algo-1:26 INFO hook.py:591] name:layer1.2.bn3.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.934 algo-1:26 INFO hook.py:591] name:layer2.0.conv1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.935 algo-1:26 INFO hook.py:591] name:layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.935 algo-1:26 INFO hook.py:591] name:layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.935 algo-1:26 INFO hook.py:591] name:layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.936 algo-1:26 INFO hook.py:591] name:layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.936 algo-1:26 INFO hook.py:591] name:layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.936 algo-1:26 INFO hook.py:591] name:layer2.0.conv3.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.937 algo-1:26 INFO hook.py:591] name:layer2.0.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.937 algo-1:26 INFO hook.py:591] name:layer2.0.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.938 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.938 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.938 algo-1:26 INFO hook.py:591] name:layer2.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.939 algo-1:26 INFO hook.py:591] name:layer2.1.conv1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.939 algo-1:26 INFO hook.py:591] name:layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.940 algo-1:26 INFO hook.py:591] name:layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.940 algo-1:26 INFO hook.py:591] name:layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.940 algo-1:26 INFO hook.py:591] name:layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.941 algo-1:26 INFO hook.py:591] name:layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.941 algo-1:26 INFO hook.py:591] name:layer2.1.conv3.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.942 algo-1:26 INFO hook.py:591] name:layer2.1.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.942 algo-1:26 INFO hook.py:591] name:layer2.1.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.943 algo-1:26 INFO hook.py:591] name:layer2.2.conv1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.943 algo-1:26 INFO hook.py:591] name:layer2.2.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.943 algo-1:26 INFO hook.py:591] name:layer2.2.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.944 algo-1:26 INFO hook.py:591] name:layer2.2.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.944 algo-1:26 INFO hook.py:591] name:layer2.2.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.945 algo-1:26 INFO hook.py:591] name:layer2.2.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.945 algo-1:26 INFO hook.py:591] name:layer2.2.conv3.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.945 algo-1:26 INFO hook.py:591] name:layer2.2.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.946 algo-1:26 INFO hook.py:591] name:layer2.2.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.946 algo-1:26 INFO hook.py:591] name:layer2.3.conv1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.947 algo-1:26 INFO hook.py:591] name:layer2.3.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.947 algo-1:26 INFO hook.py:591] name:layer2.3.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.947 algo-1:26 INFO hook.py:591] name:layer2.3.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.948 algo-1:26 INFO hook.py:591] name:layer2.3.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.948 algo-1:26 INFO hook.py:591] name:layer2.3.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.949 algo-1:26 INFO hook.py:591] name:layer2.3.conv3.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.949 algo-1:26 INFO hook.py:591] name:layer2.3.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.949 algo-1:26 INFO hook.py:591] name:layer2.3.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.950 algo-1:26 INFO hook.py:591] name:layer3.0.conv1.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.950 algo-1:26 INFO hook.py:591] name:layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.951 algo-1:26 INFO hook.py:591] name:layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.951 algo-1:26 INFO hook.py:591] name:layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.952 algo-1:26 INFO hook.py:591] name:layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.952 algo-1:26 INFO hook.py:591] name:layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.952 algo-1:26 INFO hook.py:591] name:layer3.0.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.953 algo-1:26 INFO hook.py:591] name:layer3.0.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.953 algo-1:26 INFO hook.py:591] name:layer3.0.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.954 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.0.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.954 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.1.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.954 algo-1:26 INFO hook.py:591] name:layer3.0.downsample.1.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.955 algo-1:26 INFO hook.py:591] name:layer3.1.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.955 algo-1:26 INFO hook.py:591] name:layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.956 algo-1:26 INFO hook.py:591] name:layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.956 algo-1:26 INFO hook.py:591] name:layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.956 algo-1:26 INFO hook.py:591] name:layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.957 algo-1:26 INFO hook.py:591] name:layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.957 algo-1:26 INFO hook.py:591] name:layer3.1.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.957 algo-1:26 INFO hook.py:591] name:layer3.1.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.958 algo-1:26 INFO hook.py:591] name:layer3.1.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.958 algo-1:26 INFO hook.py:591] name:layer3.2.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.959 algo-1:26 INFO hook.py:591] name:layer3.2.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.959 algo-1:26 INFO hook.py:591] name:layer3.2.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.959 algo-1:26 INFO hook.py:591] name:layer3.2.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.960 algo-1:26 INFO hook.py:591] name:layer3.2.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.960 algo-1:26 INFO hook.py:591] name:layer3.2.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.960 algo-1:26 INFO hook.py:591] name:layer3.2.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.961 algo-1:26 INFO hook.py:591] name:layer3.2.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.961 algo-1:26 INFO hook.py:591] name:layer3.2.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.961 algo-1:26 INFO hook.py:591] name:layer3.3.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.962 algo-1:26 INFO hook.py:591] name:layer3.3.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.962 algo-1:26 INFO hook.py:591] name:layer3.3.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.963 algo-1:26 INFO hook.py:591] name:layer3.3.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.963 algo-1:26 INFO hook.py:591] name:layer3.3.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.963 algo-1:26 INFO hook.py:591] name:layer3.3.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.964 algo-1:26 INFO hook.py:591] name:layer3.3.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.964 algo-1:26 INFO hook.py:591] name:layer3.3.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.964 algo-1:26 INFO hook.py:591] name:layer3.3.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.965 algo-1:26 INFO hook.py:591] name:layer3.4.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.965 algo-1:26 INFO hook.py:591] name:layer3.4.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.966 algo-1:26 INFO hook.py:591] name:layer3.4.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.966 algo-1:26 INFO hook.py:591] name:layer3.4.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.966 algo-1:26 INFO hook.py:591] name:layer3.4.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.967 algo-1:26 INFO hook.py:591] name:layer3.4.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.967 algo-1:26 INFO hook.py:591] name:layer3.4.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.968 algo-1:26 INFO hook.py:591] name:layer3.4.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.968 algo-1:26 INFO hook.py:591] name:layer3.4.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.968 algo-1:26 INFO hook.py:591] name:layer3.5.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.969 algo-1:26 INFO hook.py:591] name:layer3.5.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.969 algo-1:26 INFO hook.py:591] name:layer3.5.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.969 algo-1:26 INFO hook.py:591] name:layer3.5.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.970 algo-1:26 INFO hook.py:591] name:layer3.5.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.970 algo-1:26 INFO hook.py:591] name:layer3.5.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.971 algo-1:26 INFO hook.py:591] name:layer3.5.conv3.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.971 algo-1:26 INFO hook.py:591] name:layer3.5.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.971 algo-1:26 INFO hook.py:591] name:layer3.5.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.972 algo-1:26 INFO hook.py:591] name:layer4.0.conv1.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.972 algo-1:26 INFO hook.py:591] name:layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.972 algo-1:26 INFO hook.py:591] name:layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.973 algo-1:26 INFO hook.py:591] name:layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.973 algo-1:26 INFO hook.py:591] name:layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.974 algo-1:26 INFO hook.py:591] name:layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.974 algo-1:26 INFO hook.py:591] name:layer4.0.conv3.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.974 algo-1:26 INFO hook.py:591] name:layer4.0.bn3.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.975 algo-1:26 INFO hook.py:591] name:layer4.0.bn3.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.975 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.0.weight count_params:2097152\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.975 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.1.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.976 algo-1:26 INFO hook.py:591] name:layer4.0.downsample.1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.976 algo-1:26 INFO hook.py:591] name:layer4.1.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.977 algo-1:26 INFO hook.py:591] name:layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.977 algo-1:26 INFO hook.py:591] name:layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.977 algo-1:26 INFO hook.py:591] name:layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.978 algo-1:26 INFO hook.py:591] name:layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.978 algo-1:26 INFO hook.py:591] name:layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.978 algo-1:26 INFO hook.py:591] name:layer4.1.conv3.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.979 algo-1:26 INFO hook.py:591] name:layer4.1.bn3.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.979 algo-1:26 INFO hook.py:591] name:layer4.1.bn3.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.980 algo-1:26 INFO hook.py:591] name:layer4.2.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.980 algo-1:26 INFO hook.py:591] name:layer4.2.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.980 algo-1:26 INFO hook.py:591] name:layer4.2.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.981 algo-1:26 INFO hook.py:591] name:layer4.2.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.981 algo-1:26 INFO hook.py:591] name:layer4.2.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.981 algo-1:26 INFO hook.py:591] name:layer4.2.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.982 algo-1:26 INFO hook.py:591] name:layer4.2.conv3.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.982 algo-1:26 INFO hook.py:591] name:layer4.2.bn3.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.983 algo-1:26 INFO hook.py:591] name:layer4.2.bn3.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.983 algo-1:26 INFO hook.py:591] name:fc.weight count_params:2048000\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.983 algo-1:26 INFO hook.py:591] name:fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.984 algo-1:26 INFO hook.py:593] Total Trainable Params: 25557032\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.984 algo-1:26 INFO hook.py:425] Monitoring the collections: relu_input, losses, gradients\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:23.986 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/prestepzero-*-start-1642676642005017.8_train-0-stepstart-1642676663985963.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:24.005 algo-1:26 INFO hook.py:488] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:39.175 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-stepstart-1642676663997584.0_train-0-forwardpassend-1642676679175351.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:04:45.066 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-forwardpassend-1642676679178545.8_train-1-stepstart-1642676685064848.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:06:04.909 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-1-stepstart-1642676685071699.0_train-1-forwardpassend-1642676764909207.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:06:09.636 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-1-forwardpassend-1642676764912067.8_train-2-stepstart-1642676769635631.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:07:26.217 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-2-stepstart-1642676769639057.2_train-2-forwardpassend-1642676846217399.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:07:30.955 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-2-forwardpassend-1642676846219115.2_train-3-stepstart-1642676850954692.2/python_stats.\u001b[0m\n",
      "VanishingGradient: InProgress\n",
      "Overfit: Error\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: Error\n",
      "LossNotDecreasing: InProgress\n",
      "\u001b[34m[2022-01-20 11:08:47.349 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-3-stepstart-1642676850958369.2_train-3-forwardpassend-1642676927349358.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:08:52.063 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-3-forwardpassend-1642676927351255.8_train-4-stepstart-1642676932062315.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:10:08.651 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-4-stepstart-1642676932066359.5_train-4-forwardpassend-1642677008650878.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:10:13.416 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-4-forwardpassend-1642677008653136.0_train-5-stepstart-1642677013415186.0/python_stats.\u001b[0m\n",
      "LowGPUUtilization: IssuesFound\n",
      "ProfilerReport: Error\n",
      "\u001b[34m[2022-01-20 11:11:30.393 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-5-stepstart-1642677013419070.5_train-5-forwardpassend-1642677090393341.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:11:35.104 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-5-forwardpassend-1642677090395415.0_train-6-stepstart-1642677095103592.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:12:52.562 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-6-stepstart-1642677095106684.2_train-6-forwardpassend-1642677172562092.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:12:57.331 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-6-forwardpassend-1642677172563850.0_train-7-stepstart-1642677177330301.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:14:14.372 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-7-stepstart-1642677177333777.8_train-7-forwardpassend-1642677254372555.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:14:19.117 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-7-forwardpassend-1642677254374385.5_train-8-stepstart-1642677259116928.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:15:36.525 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-8-stepstart-1642677259120202.0_train-8-forwardpassend-1642677336525034.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:15:41.273 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-8-forwardpassend-1642677336526851.8_train-9-stepstart-1642677341272672.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:16:58.442 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-9-stepstart-1642677341276423.5_train-9-forwardpassend-1642677418441763.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-01-20 11:17:03.251 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-9-forwardpassend-1642677418443623.0_train-10-stepstart-1642677423250997.5/python_stats.\u001b[0m\n",
      "\u001b[34mSTART VALIDATING\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "print(f\"Training jobname: {training_job_name}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "from smdebug.core.modes import ModeKeys\n",
    "\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Can you print the names of all the tensors that were tracked\n",
    "print(trial.tensor_names())\n",
    "# TODO: Can you print the number of datapoints for one of those tensors\n",
    "# for both train and eval mode\n",
    "print(len(trial.tensor(\"CrossEntropyLoss_output_0\").steps(mode=ModeKeys.TRAIN)))\n",
    "print(len(trial.tensor(\"CrossEntropyLoss_output_0\").steps(mode=ModeKeys.EVAL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "\n",
    "tj = TrainingJob(training_job_name, region)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "\n",
    "system_metrics_reader = tj.get_systems_metrics_reader()\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "\n",
    "view_timeline_charts = TimelineCharts(\n",
    "    system_metrics_reader,\n",
    "    framework_metrics_reader=None,\n",
    "    select_dimensions=[\"CPU\", \"GPU\"],\n",
    "    select_events=[\"total\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "print(f\"You will find the profiler report in {rule_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "! aws s3 ls {rule_output_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "! aws s3 cp {rule_output_path} ./ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get the autogenerated folder name of profiler report\n",
    "profiler_report_name = [\n",
    "    rule[\"RuleConfigurationName\"]\n",
    "    for rule in estimator.latest_training_job.rule_job_summary()\n",
    "    if \"Profiler\" in rule[\"RuleConfigurationName\"]\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.HTML(filename=profiler_report_name + \"/profiler-output/profiler-report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
